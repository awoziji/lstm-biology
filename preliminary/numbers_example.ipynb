{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-20T15:03:10.910000",
     "start_time": "2016-03-20T15:03:08.239000"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "D:\\Python\\27_32bit\\lib\\site-packages\\theano\\tensor\\signal\\downsample.py:5: UserWarning: downsample module has been moved to the pool module.\n",
      "  warnings.warn(\"downsample module has been moved to the pool module.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nThis script generates a sequence of numbers, then passes a portion of them 1 at a time to an LSTM \\nwhich is then trained to guess the next number. The LSTM is then tested on its ability to guess the\\nremaining numbers. A stateful LSTM network is used, so only the most recent time step needs to be \\npassed in order for the network to learn. \\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import print_function\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "\n",
    "'''\n",
    "This script generates a sequence of numbers, then passes a portion of them 1 at a time to an LSTM \n",
    "which is then trained to guess the next number. The LSTM is then tested on its ability to guess the\n",
    "remaining numbers. A stateful LSTM network is used, so only the most recent time step needs to be \n",
    "passed in order for the network to learn. \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-20T15:03:10.926000",
     "start_time": "2016-03-20T15:03:10.915000"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = [.1 , .1 , .4 , .1 , .2 ]\n",
    "data = data * 300\n",
    "#numOfPrevSteps = 1 # We will only pass in 1 timestep at a time. The network will guess the next step from the previous step and its internal state.\n",
    "batchSize = 1 # We are only tracking a single set of features through time per epoch.\n",
    "featurelen = 1 # Only a single feature is being trained on. If our data was guess a list of numbers instead of 1 number each time, this would be set equal to the length of that list.\n",
    "testingSize = 100 # 100 data points will be used as a test set\n",
    "totalTimeSteps = len(data) # Each element in the data represents one timestep of our single feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-20T15:03:10.948000",
     "start_time": "2016-03-20T15:03:10.933000"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formatting Data\n",
      "Formatted Data  [[[ 0.1]\n",
      "  [ 0.1]\n",
      "  [ 0.4]\n",
      "  ..., \n",
      "  [ 0.4]\n",
      "  [ 0.1]\n",
      "  [ 0.2]]]\n"
     ]
    }
   ],
   "source": [
    "print('Formatting Data')\n",
    "'''\n",
    "The data must be converted into a list of matrices to be fed to our network.\n",
    "In this case, one matrix must be generated for item in the batch. Our batchsize\n",
    "is 1, so there will only be 1 matrix in this list. The matrix consists of a list\n",
    "of features. Each row has 1 column per feature. There is 1 column in the matrix \n",
    "per timestep.\n",
    "\n",
    "So the final form of the data will be a list containing a single matrix, which has \n",
    "1 row per timestep, and only 1 column because we only have 1 feature. \n",
    "'''\n",
    "X = np.zeros([batchSize, totalTimeSteps , featurelen]) \n",
    "for r in range(totalTimeSteps):\n",
    "    X[0][r] = data[r]\n",
    "print('Formatted Data ',X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-20T15:03:10.964000",
     "start_time": "2016-03-20T15:03:10.953000"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1500, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape  # batchSize=1, totalTimeSteps=1500, featurelen=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-18T15:38:43.868000",
     "start_time": "2016-03-18T15:37:20.479000"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Building model...')\n",
    "'''\n",
    "This problem is very simple, so only 2 layers with 10 nodes\n",
    "each are used. For more complicated data, more numerous and \n",
    "larger layers will likely be required. This data is very simple and \n",
    "could probably be trained off of only 1 layer. Remember to set \n",
    "return_sequences=False for the last hidden layer.\n",
    "'''\n",
    "model = Sequential()\n",
    "model.add(LSTM(10 ,return_sequences=True, batch_input_shape=(batchSize, 1 , featurelen), stateful=True))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(LSTM(10 , return_sequences=False,stateful=True))\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Dense( featurelen ))\n",
    "model.add(Activation('linear'))\n",
    "model.compile(loss='mean_squared_error', optimizer='rmsprop')\n",
    "model.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-20T15:03:16.100000",
     "start_time": "2016-03-20T15:03:16.041000"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Layer implementing a Gaussian mixture model, see https://github.com/fchollet/keras/issues/1061\n",
    "\n",
    "from keras.layers import Layer\n",
    "#from keras import backend as T\n",
    "# TODO: This is only implemented for theano, rewrite it using keras.backend (as an exercise).\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "class GMMActivation(Layer):\n",
    "    \"\"\"\n",
    "    GMM-like activation function.\n",
    "    Assumes that input has (D+2)*M dimensions, where D is the dimensionality of the \n",
    "    target data. The first M*D features are treated as means, the next M features as \n",
    "    standard devs and the last M features as mixture components of the GMM. \n",
    "    \"\"\"\n",
    "    def __init__(self, M, **kwargs):\n",
    "        super(GMMActivation, self).__init__(**kwargs)\n",
    "        self.M = M\n",
    "\n",
    "    def get_output(self, train=False):\n",
    "        X = self.get_input(train)\n",
    "        D = T.shape(X)[1]/self.M - 2\n",
    "        # leave mu values as they are since they're unconstrained\n",
    "        # scale sigmas with exp, s.t. all values are non-negative \n",
    "        X = T.set_subtensor(X[:,D*self.M:(D+1)*self.M], T.exp(X[:,D*self.M:(D+1)*self.M]))\n",
    "        # scale alphas with softmax, s.t. that all values are between [0,1] and sum up to 1\n",
    "        X = T.set_subtensor(X[:,(D+1)*self.M:(D+2)*self.M], T.nnet.softmax(X[:,(D+1)*self.M:(D+2)*self.M]))\n",
    "        return X\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\"name\": self.__class__.__name__,\n",
    "                  \"M\": self.M}\n",
    "        base_config = super(GMMActivation, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "def gmm_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    GMM loss function.\n",
    "    Assumes that y_pred has (D+2)*M dimensions and y_true has D dimensions. The first \n",
    "    M*D features are treated as means, the next M features as standard devs and the last \n",
    "    M features as mixture components of the GMM. \n",
    "    \"\"\"\n",
    "    def loss(m, M, D, y_true, y_pred):\n",
    "        mu = y_pred[:,D*m:(m+1)*D]\n",
    "        sigma = y_pred[:,D*M+m]\n",
    "        alpha = y_pred[:,(D+1)*M+m]\n",
    "        return (alpha/sigma) * T.exp(-T.sum(T.sqr(mu-y_true),-1)/(2*sigma**2))\n",
    "\n",
    "    D = T.shape(y_true)[1]\n",
    "    M = T.shape(y_pred)[1]/(D+2)\n",
    "    seq = T.arange(M)\n",
    "    result, _ = theano.scan(fn=loss, outputs_info=None, \n",
    "    sequences=seq, non_sequences=[M, D, y_true, y_pred])\n",
    "    return -T.log(result.sum(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-20T15:16:24.434000",
     "start_time": "2016-03-20T15:15:04.257000"
    },
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python\\27_32bit\\lib\\site-packages\\ipykernel\\__main__.py:22: DeprecationWarning: Division of two integer types with x / y is deprecated, please use x // y for an integer division.\n",
      "D:\\Python\\27_32bit\\lib\\site-packages\\ipykernel\\__main__.py:50: DeprecationWarning: Division of two integer types with x / y is deprecated, please use x // y for an integer division.\n"
     ]
    }
   ],
   "source": [
    "# Alternative model with mixture density network.\n",
    "from keras.optimizers import RMSprop\n",
    "model = Sequential()\n",
    "model.add(LSTM(10 ,return_sequences=True, batch_input_shape=(batchSize, 1 , featurelen), stateful=True))\n",
    "# TODO: Reenable dropout.\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(LSTM(10 , return_sequences=False,stateful=True))\n",
    "#model.add(Dropout(0.2))\n",
    "num_gaussians_per_dimension = 10  # TODO: Change this parameter.\n",
    "model.add(Dense( (featurelen+2) * num_gaussians_per_dimension ))\n",
    "model.add(GMMActivation(num_gaussians_per_dimension))\n",
    "model.compile(loss=gmm_loss, optimizer=RMSprop(lr=0.0001))  # speed of learning: rmsprop > adam >> sgd\n",
    "model.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-20T15:24:22.948000",
     "start_time": "2016-03-20T15:16:24.436000"
    },
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting training\n",
      "Epoch 1 - loss: -0.378322\n",
      "Epoch 2 - loss: -1.60644\n",
      "Epoch 3 - loss: -2.10905\n",
      "Epoch 4 - loss: -2.90427\n",
      "Epoch 5 - loss: -3.79568\n",
      "Epoch 6 - loss: -4.49112\n",
      "Epoch 7 - loss: -4.79431\n",
      "Epoch 8 - loss: -4.91689\n",
      "Epoch 9 - loss: -5.07241\n",
      "Epoch 10 - loss: -5.16247\n",
      "Epoch 11 - loss: -5.19246\n",
      "Epoch 12 - loss: -5.28407\n",
      "Epoch 13 - loss: -5.27383\n",
      "Epoch 14 - loss: -5.30333\n",
      "Epoch 15 - loss: -5.30905\n",
      "Epoch 16 - loss: -5.31722\n",
      "Epoch 17 - loss: -5.32319\n",
      "Epoch 18 - loss: -5.31891\n",
      "Epoch 19 - loss: -5.32005\n",
      "Epoch 20 - loss: -5.34503\n",
      "Epoch 21 - loss: -5.32751\n",
      "Epoch 22 - loss: -5.31124\n",
      "Epoch 23 - loss: -5.35417\n",
      "Epoch 24 - loss: -5.35706\n",
      "Epoch 25 - loss: -5.34621\n",
      "Epoch 26 - loss: -5.34918\n",
      "Epoch 27 - loss: -5.35616\n",
      "Epoch 28 - loss: -5.34844\n",
      "Epoch 29 - loss: -5.36161\n",
      "Epoch 30 - loss: -5.36579\n",
      "Epoch 31 - loss: -5.38031\n",
      "Epoch 32 - loss: -5.37441\n",
      "Epoch 33 - loss: -5.37084\n",
      "Epoch 34 - loss: -5.37196\n",
      "Epoch 35 - loss: -5.38599\n",
      "Epoch 36 - loss: -5.38828\n",
      "Epoch 37 - loss: -5.37994\n",
      "Epoch 38 - loss: -5.38042\n",
      "Epoch 39 - loss: -5.39181\n",
      "Epoch 40 - loss: -5.37\n",
      "Epoch 41 - loss: -5.38485\n",
      "Epoch 42 - loss: -5.38386\n",
      "Epoch 43 - loss: -5.39382\n",
      "Epoch 44 - loss: -5.40482\n",
      "Epoch 45 - loss: -5.40324\n",
      "Epoch 46 - loss: -5.4021\n",
      "Epoch 47 - loss: -5.41584\n",
      "Epoch 48 - loss: -5.39403\n",
      "Epoch 49 - loss: -5.39997\n",
      "Epoch 50 - loss: -5.41027\n",
      "Epoch 51 - loss: -5.39879\n",
      "Epoch 52 - loss: -5.41377\n",
      "Epoch 53 - loss: -5.40782\n",
      "Epoch 54 - loss: -5.41054\n",
      "Epoch 55 - loss: -5.39801\n",
      "Epoch 56 - loss: -5.43289\n",
      "Epoch 57 - loss: -5.43549\n",
      "Epoch 58 - loss: -5.43975\n",
      "Epoch 59 - loss: -5.4365\n",
      "Epoch 60 - loss: -5.43942\n",
      "Epoch 61 - loss: -5.4324\n",
      "Epoch 62 - loss: -5.44825\n",
      "Epoch 63 - loss: -5.42788\n",
      "Epoch 64 - loss: -5.42656\n",
      "Epoch 65 - loss: -5.43455\n",
      "Epoch 66 - loss: -5.4281\n",
      "Epoch 67 - loss: -5.4362\n",
      "Epoch 68 - loss: -5.43098\n",
      "Epoch 69 - loss: -5.44329\n",
      "Epoch 70 - loss: -5.4365\n",
      "Epoch 71 - loss: -5.44545\n",
      "Epoch 72 - loss: -5.43372\n",
      "Epoch 73 - loss: -5.44915\n",
      "Epoch 74 - loss: -5.44856\n",
      "Epoch 75 - loss: -5.45337\n",
      "Epoch 76 - loss: -5.44287\n",
      "Epoch 77 - loss: -5.45934\n",
      "Epoch 78 - loss: -5.45239\n",
      "Epoch 79 - loss: -5.45664\n",
      "Epoch 80 - loss: -5.44639\n",
      "Epoch 81 - loss: -5.45636\n",
      "Epoch 82 - loss: -5.44119\n",
      "Epoch 83 - loss: -5.46531\n",
      "Epoch 84 - loss: -5.45119\n",
      "Epoch 85 - loss: -5.46449\n",
      "Epoch 86 - loss: -5.4531\n",
      "Epoch 87 - loss: -5.44594\n",
      "Epoch 88 - loss: -5.45447\n",
      "Epoch 89 - loss: -5.44898\n",
      "Epoch 90 - loss: -5.46282\n",
      "Epoch 91 - loss: -5.4636\n",
      "Epoch 92 - loss: -5.45115\n",
      "Epoch 93 - loss: -5.44968\n",
      "Epoch 94 - loss: -5.46245\n",
      "Epoch 95 - loss: -5.45182\n",
      "Epoch 96 - loss: -5.453\n",
      "Epoch 97 - loss: -5.4536\n",
      "Epoch 98 - loss: -5.45499\n",
      "Epoch 99 - loss: -5.45768\n",
      "Epoch 100 - loss: -5.46011\n",
      "training complete\n"
     ]
    }
   ],
   "source": [
    "print('starting training')\n",
    "num_epochs = 100\n",
    "model.reset_states()\n",
    "for e in range(num_epochs):\n",
    "    losses_epoch = []\n",
    "    print('Epoch', e+1, end='')\n",
    "    for i in range(0,totalTimeSteps-testingSize):\n",
    "        result = model.train_on_batch(X[:, i:i+1, :], np.reshape(X[:, i+1, :], (batchSize, featurelen)) ) # Train on guessing a single element based on the previous element\n",
    "        losses_epoch.append(result[0])\n",
    "    print(' - loss:', np.mean(losses_epoch))\n",
    "    model.reset_states()\n",
    "print('training complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-20T15:53:56.815000",
     "start_time": "2016-03-20T15:53:56.001000"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warming up on training data\n"
     ]
    }
   ],
   "source": [
    "print('warming up on training data')  # Predict on all training data in order to warm up for testing data\n",
    "model.reset_states()\n",
    "warmupPredictions = []\n",
    "for i in range(0,totalTimeSteps-testingSize ):    \n",
    "    pred_parameters = model.predict(X[:, i:i+1, :] )\n",
    "    means = pred_parameters[0, :num_gaussians_per_dimension * featurelen]\n",
    "    sds = pred_parameters[0, num_gaussians_per_dimension * featurelen:num_gaussians_per_dimension * (featurelen + 1)]\n",
    "    weights = pred_parameters[0, num_gaussians_per_dimension * (featurelen + 1):]\n",
    "    pred = np.sum(weights * np.random.normal(means, sds))\n",
    "    warmupPredictions.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-20T15:53:57.256000",
     "start_time": "2016-03-20T15:53:57.131000"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing network\n"
     ]
    }
   ],
   "source": [
    "# Generate new data by using training data as input.\n",
    "# RUN WARMUP BEFORE THIS.\n",
    "print('testing network')\n",
    "predictions = []\n",
    "testStart = totalTimeSteps-testingSize -1 #We subtract one because we want the last element of the training set to be first element of the testing set\n",
    "for i in range(testStart,totalTimeSteps-1):\n",
    "    pred_parameters = model.predict(X[:, i:i+1, :] )\n",
    "    means = pred_parameters[0, :num_gaussians_per_dimension * featurelen]\n",
    "    sds = pred_parameters[0, num_gaussians_per_dimension * featurelen:num_gaussians_per_dimension * (featurelen + 1)]\n",
    "    weights = pred_parameters[0, num_gaussians_per_dimension * (featurelen + 1):]\n",
    "    pred = np.sum(weights * np.random.normal(means, sds))\n",
    "    predictions.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-20T02:54:12.597000",
     "start_time": "2016-03-20T02:54:12.497000"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate new data by using predictions as input.\n",
    "# RUN WARMUP BEFORE THIS.\n",
    "predictions = []\n",
    "#print(warmupPredictions)\n",
    "predictions.append(warmupPredictions[-1])\n",
    "testStart = totalTimeSteps-testingSize -1 #We subtract one because we want the last element of the training set to be first element of the testing set\n",
    "for i in range(testStart,totalTimeSteps-2):\n",
    "    pred_parameters = model.predict(predictions[-1][np.newaxis, np.newaxis, np.newaxis])\n",
    "    means = pred_parameters[0, :num_gaussians_per_dimension * featurelen]\n",
    "    sds = pred_parameters[0, num_gaussians_per_dimension * featurelen:num_gaussians_per_dimension * (featurelen + 1)]\n",
    "    weights = pred_parameters[0, num_gaussians_per_dimension * (featurelen + 1):]\n",
    "    pred = np.sum(weights * np.random.normal(means, sds))\n",
    "    predictions.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-20T15:54:00.841000",
     "start_time": "2016-03-20T15:54:00.418000"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x38c06490>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEPCAYAAABGP2P1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGBRFUZQo/n8BLN+zLiiixQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x38c064f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(predictions, label='predicted')\n",
    "plt.plot(data[testStart+1:], label='expected')\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('value')\n",
    "#plt.xlim(-10, len(predictions) + 10)\n",
    "plt.xlim(10, 50)\n",
    "plt.ylim(0, 0.5)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-20T02:55:15.577000",
     "start_time": "2016-03-20T02:55:15.093000"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Predict with random values as seeds.\n",
    "len_seed = 1\n",
    "predictTimeSteps = 200\n",
    "predicted = np.zeros((batchSize, predictTimeSteps, featurelen))\n",
    "predicted[:, :len_seed] = np.random.rand(batchSize, 1, featurelen)  #2. * (np.random.rand(batch_size, 1, 3) - 0.5)\n",
    "model.reset_states()\n",
    "\n",
    "log_traj = 0\n",
    "    \n",
    "# for i in range(len_seed - 1):\n",
    "# #     print seed[:, i:i+1]\n",
    "#     model_input = seed[:, i:i+1]\n",
    "#     model_output = model.predict_on_batch(model_input)[0]\n",
    "#     print 'Trajectory {}: Input: {} - Output: {}'.format(log_traj, model_input[log_traj], model_output[log_traj])\n",
    "    \n",
    "    \n",
    "# print '------------------------'\n",
    "    \n",
    "for i in range(predictTimeSteps - 1):\n",
    "    model_input = predicted[:, i:i+1]\n",
    "    model_output = model.predict_on_batch(model_input)[0]    \n",
    "    #model_output += 0.01 * (np.random.rand(batch_size, 3) - 0.5)\n",
    "    \n",
    "    print('Tr {}, step {}: In: {} - Out: {}'.format(log_traj, i, model_input[log_traj], model_output[log_traj]))\n",
    "    \n",
    "    if i+1 >= len_seed:\n",
    "        predicted[:, i+1] = model_output\n",
    "        print('--> Storing at {}'.format(i+1))\n",
    "    else:\n",
    "        print('--> Seed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-18T15:49:35.859000",
     "start_time": "2016-03-18T15:49:35.621000"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(predicted[0], 'b')\n",
    "#plt.plot(range(len(predictions)), [t[0] for t in targets], 'g')\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('value')\n",
    "plt.xlim(-10, len(predicted[0]) + 10)\n",
    "plt.ylim(-0.5, 1)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
