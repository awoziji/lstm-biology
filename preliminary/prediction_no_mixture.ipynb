{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-18T18:57:30.402000",
     "start_time": "2016-03-18T18:57:29.951000"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-18T18:57:32.008000",
     "start_time": "2016-03-18T18:57:30.406000"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category plastic: Found 177 files, created 885 trajectories\n"
     ]
    }
   ],
   "source": [
    "# Read all data files of one category.\n",
    "import os\n",
    "\n",
    "category = 'plastic'\n",
    "downsample_steps = {'alive': 2, 'fibro': 5, 'plastic': 5}  # TODO: Rename var.\n",
    "\n",
    "data_dir = 'data/JulianTrajs/' + category\n",
    "trajectories = []\n",
    "filenames = os.listdir(data_dir)    \n",
    "for filename in filenames:\n",
    "    trajectory = np.genfromtxt(os.path.join(data_dir, filename))\n",
    "    for start in range(downsample_steps[category]):\n",
    "        end = -(downsample_steps[category] - start)\n",
    "        sliced_trajectory = trajectory[start:end:downsample_steps[category]]\n",
    "        trajectories.append(sliced_trajectory)\n",
    "trajectories = np.array(trajectories)\n",
    "print \"Category {}: Found {} files, created {} trajectories\".format(category, len(filenames), len(trajectories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-18T18:57:32.017000",
     "start_time": "2016-03-18T18:57:32.012000"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_velocities(x, multiple_trajectories=False):\n",
    "    return np.diff(x, axis=int(multiple_trajectories)) / 5.\n",
    "# TODO: Does only work for single trajectory right now, extend to multiple trajectories if needed.\n",
    "def to_positions(x):\n",
    "    return np.append(np.zeros((1, 3)), np.cumsum(x * 5., axis=0), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-18T18:57:32.030000",
     "start_time": "2016-03-18T18:57:32.020000"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trajectories = to_velocities(trajectories, multiple_trajectories=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-18T18:57:32.047000",
     "start_time": "2016-03-18T18:57:32.033000"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.8507712\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1843186961678816"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize trajectories to [-1, 1] for the LSTM network (it outputs values between -1 and 1 by default)\n",
    "# TODO: Do not use min/max values here but fixed value to generalize to other datasets.\n",
    "min_value = np.min(trajectories)\n",
    "max_value = np.max(trajectories)\n",
    "abs_max_value = max(abs(min_value), abs(max_value))\n",
    "print abs_max_value\n",
    "def normalize(x):\n",
    "    return x / abs_max_value\n",
    "    #return np.interp(x, [min_value, max_value], [-1., 1.])\n",
    "def denormalize(x):\n",
    "    return x * abs_max_value\n",
    "    #return np.interp(x, [-1., 1.], [min_value, max_value])\n",
    "    \n",
    "normalize(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-18T18:57:32.268000",
     "start_time": "2016-03-18T18:57:32.262000"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trajectories = normalize(trajectories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-18T18:57:33.550000",
     "start_time": "2016-03-18T18:57:33.547000"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = len(trajectories)\n",
    "num_timesteps = len(trajectories[0])\n",
    "#num_timesteps_per_epoch = 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-18T18:58:42.648000",
     "start_time": "2016-03-18T18:57:34.144000"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce 840M (CNMeM is disabled, CuDNN not available)\n",
      "D:\\Python\\27_32bit\\lib\\site-packages\\theano\\tensor\\signal\\downsample.py:5: UserWarning: downsample module has been moved to the pool module.\n",
      "  warnings.warn(\"downsample module has been moved to the pool module.\")\n"
     ]
    }
   ],
   "source": [
    "# Set up the network.\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.layers import LSTM\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Feed in one time step at a time.\n",
    "model.add(LSTM(batch_input_shape=(batch_size, 1, 3), output_dim=10, return_sequences=False, stateful=True))\n",
    "# model.add(LSTM(batch_input_shape=(batch_size, 1, 3), output_dim=100, return_sequences=True, stateful=True))\n",
    "\n",
    "#model.add(Dropout(0.3))\n",
    "#model.add(LSTM(output_dim=100, return_sequences=True, stateful=True))\n",
    "#model.add(LSTM(output_dim=100, return_sequences=True, stateful=True))\n",
    "\n",
    "\n",
    "#model.add(LSTM(output_dim=100, return_sequences=True, stateful=True))\n",
    "#model.add(LSTM(output_dim=100, return_sequences=False, stateful=True))\n",
    "model.add(Dense(output_dim=3))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='rmsprop')\n",
    "model.reset_states()  # TODO: Is this necessary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-18T18:58:42.654000",
     "start_time": "2016-03-18T18:58:42.650000"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-18T19:14:57.466000",
     "start_time": "2016-03-18T18:58:42.658000"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - loss: 0.00242808\n",
      "Epoch 2 - loss: 0.0022587\n",
      "Epoch 3 - loss: 0.00216513\n",
      "Epoch 4 - loss: 0.00210526\n",
      "Epoch 5 - loss: 0.00206357\n",
      "Epoch 6 - loss: 0.00203296\n",
      "Epoch 7 - loss: 0.00200966\n",
      "Epoch 8 - loss: 0.00199141\n",
      "Epoch 9 - loss: 0.00197674\n",
      "Epoch 10 - loss: 0.00196469\n",
      "Epoch 11 - loss: 0.00195457\n",
      "Epoch 12 - loss: 0.00194592\n",
      "Epoch 13 - loss: 0.0019384\n",
      "Epoch 14 - loss: 0.00193178\n",
      "Epoch 15 - loss: 0.00192589\n",
      "Epoch 16 - loss: 0.00192059\n",
      "Epoch 17 - loss: 0.00191579\n",
      "Epoch 18 - loss: 0.00191143\n",
      "Epoch 19 - loss: 0.00190744\n",
      "Epoch 20 - loss: 0.00190378\n",
      "Epoch 21 - loss: 0.00190041\n",
      "Epoch 22 - loss: 0.0018973\n",
      "Epoch 23 - loss: 0.00189443\n",
      "Epoch 24 - loss: 0.00189176\n",
      "Epoch 25 - loss: 0.00188929\n",
      "Epoch 26 - loss: 0.001887\n",
      "Epoch 27 - loss: 0.00188487\n",
      "Epoch 28 - loss: 0.00188288\n",
      "Epoch 29 - loss: 0.00188103\n",
      "Epoch 30 - loss: 0.00187931\n",
      "Epoch 31 - loss: 0.00187769\n",
      "Epoch 32 - loss: 0.00187619\n",
      "Epoch 33 - loss: 0.00187478\n",
      "Epoch 34 - loss: 0.00187347\n",
      "Epoch 35 - loss: 0.00187224\n",
      "Epoch 36 - loss: 0.00187108\n",
      "Epoch 37 - loss: 0.00187\n",
      "Epoch 38 - loss: 0.00186899\n",
      "Epoch 39 - loss: 0.00186804\n",
      "Epoch 40 - loss: 0.00186715\n",
      "Epoch 41 - loss: 0.00186632\n",
      "Epoch 42 - loss: 0.00186554\n",
      "Epoch 43 - loss: 0.0018648\n",
      "Epoch 44 - loss: 0.00186412\n",
      "Epoch 45 - loss: 0.00186347\n",
      "Epoch 46 - loss: 0.00186287\n",
      "Epoch 47 - loss: 0.0018623\n",
      "Epoch 48 - loss: 0.00186177\n",
      "Epoch 49 - loss: 0.00186128\n",
      "Epoch 50 - loss: 0.00186081\n",
      "Epoch 51 - loss: 0.00186038\n",
      "Epoch 52 - loss: 0.00185997\n",
      "Epoch 53 - loss: 0.00185959\n",
      "Epoch 54 - loss: 0.00185924\n",
      "Epoch 55 - loss: 0.0018589\n",
      "Epoch 56 - loss: 0.0018586\n",
      "Epoch 57 - loss: 0.00185831\n",
      "Epoch 58 - loss: 0.00185804\n",
      "Epoch 59 - loss: 0.00185779\n",
      "Epoch 60 - loss: 0.00185756\n",
      "Epoch 61 - loss: 0.00185735\n",
      "Epoch 62 - loss: 0.00185715\n",
      "Epoch 63 - loss: 0.00185697\n",
      "Epoch 64 - loss: 0.0018568\n",
      "Epoch 65 - loss: 0.00185664\n",
      "Epoch 66 - loss: 0.0018565\n",
      "Epoch 67 - loss: 0.00185637\n",
      "Epoch 68 - loss: 0.00185625\n",
      "Epoch 69 - loss: 0.00185614\n",
      "Epoch 70 - loss: 0.00185604\n",
      "Epoch 71 - loss: 0.00185594\n",
      "Epoch 72 - loss: 0.00185586\n",
      "Epoch 73 - loss: 0.00185578\n",
      "Epoch 74 - loss: 0.00185571\n",
      "Epoch 75 - loss: 0.00185565\n",
      "Epoch 76 - loss: 0.0018556\n",
      "Epoch 77 - loss: 0.00185555\n",
      "Epoch 78 - loss: 0.0018555\n",
      "Epoch 79 - loss: 0.00185546\n",
      "Epoch 80 - loss: 0.00185542\n",
      "Epoch 81 - loss: 0.00185539\n",
      "Epoch 82 - loss: 0.00185537\n",
      "Epoch 83 - loss: 0.00185534\n",
      "Epoch 84 - loss: 0.00185532\n",
      "Epoch 85 - loss: 0.0018553\n",
      "Epoch 86 - loss: 0.00185528\n",
      "Epoch 87 - loss: 0.00185527\n",
      "Epoch 88 - loss: 0.00185526\n",
      "Epoch 89 - loss: 0.00185525\n",
      "Epoch 90 - loss: 0.00185524\n",
      "Epoch 91 - loss: 0.00185524\n",
      "Epoch 92 - loss: 0.00185523\n",
      "Epoch 93 - loss: 0.00185523\n",
      "Epoch 94 - loss: 0.00185522\n",
      "Epoch 95 - loss: 0.00185522\n",
      "Epoch 96 - loss: 0.00185522\n",
      "Epoch 97 - loss: 0.00185522\n",
      "Epoch 98 - loss: 0.00185522\n",
      "Epoch 99 - loss: 0.00185522\n",
      "Epoch 100 - loss: 0.00185522\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 100\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    print 'Epoch', epoch,\n",
    "    losses_epoch = []\n",
    "    for i in range(num_timesteps - 1):\n",
    "        results = model.train_on_batch(trajectories[:, i:i+1], trajectories[:, i+1])\n",
    "        losses_epoch.append(results[0])\n",
    "    mean_loss = np.mean(losses_epoch)\n",
    "    print '- loss:', mean_loss\n",
    "    losses.append(mean_loss)\n",
    "    model.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-18T02:39:04.903000",
     "start_time": "2016-03-18T02:27:18.783000"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO: Evaluate if this has a positive effect on final accuracy and/or learning speed.\n",
    "# Split up trajectories in smaller parts and reset states in between.\n",
    "num_epochs = 1000\n",
    "num_steps_per_mini_batch = 50\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    print 'Epoch', epoch,\n",
    "    losses_epoch = []\n",
    "    for start in range(0, num_timesteps - 1 - num_steps_per_mini_batch, num_steps_per_mini_batch):  # TODO: Shuffle the list created by range and see if this has an effect.\n",
    "        for i in range(start, start + num_steps_per_mini_batch):\n",
    "            results = model.train_on_batch(trajectories[:, i:i+1], trajectories[:, i+1])\n",
    "            losses_epoch.append(results[0])\n",
    "        model.reset_states()\n",
    "    mean_loss = np.mean(losses_epoch)\n",
    "    print '- loss:', mean_loss\n",
    "    losses.append(mean_loss)\n",
    "    model.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-18T18:04:45.330000",
     "start_time": "2016-03-18T18:04:44.981000"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-18T18:04:56.096000",
     "start_time": "2016-03-18T18:04:55.700000"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Predict all steps using the training data as input (i. e. not the predictions!).\n",
    "model.reset_states()\n",
    "predicted = []\n",
    "predicted.append(trajectories[:, 0])  # Take first timestep from training data so predicted and expected have the same dimensions.\n",
    "for i in range(num_timesteps - 1):\n",
    "    predicted.append(model.predict_on_batch(trajectories[:, i:i+1])[0])\n",
    "predicted = np.array(predicted)\n",
    "predicted = predicted.transpose((1, 0, 2))\n",
    "expected = trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-18T18:04:57.151000",
     "start_time": "2016-03-18T18:04:56.782000"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot single trajectory from positions.\n",
    "i_traj = 15\n",
    "pr = denormalize(predicted[i_traj])\n",
    "plt.plot(pr[:, 0], pr[:, 1], label='Predicted')\n",
    "exp = denormalize(expected[i_traj])\n",
    "plt.plot(exp[:, 0], exp[:, 1], label='Expected')\n",
    "lim = abs(max(np.min(pr), np.max(pr), np.min(exp), np.max(exp), key=abs)) + 20\n",
    "plt.xlim(-lim, lim)\n",
    "plt.ylim(-lim, lim)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-18T18:04:58.373000",
     "start_time": "2016-03-18T18:04:58.006000"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot single trajectory from velocities.\n",
    "i_traj = 10\n",
    "pr = to_positions(denormalize(predicted[i_traj]))\n",
    "plt.plot(pr[:, 0], pr[:, 1], label='Predicted')\n",
    "exp = to_positions(denormalize(expected[i_traj]))\n",
    "plt.plot(exp[:, 0], exp[:, 1], label='Expected')\n",
    "lim = abs(max(np.min(pr), np.max(pr), np.min(exp), np.max(exp), key=abs)) + 20\n",
    "plt.xlim(-lim, lim)\n",
    "plt.ylim(-lim, lim)\n",
    "plt.legend()\n",
    "#plt.plot(traj)\n",
    "\n",
    "# TODO: Due to training on velocities, predicted trajectories are often scaled versions of expected trajectories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-18T18:05:57.780000",
     "start_time": "2016-03-18T18:05:56.615000"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len_seed = 50  # TODO: Play around with seed size.\n",
    "predicted = np.zeros((batch_size, num_timesteps, 3))\n",
    "predicted[:, :len_seed] = trajectories[:, :len_seed]\n",
    "model.reset_states()\n",
    "\n",
    "log_traj = 0\n",
    "    \n",
    "for i in range(num_timesteps - 1):\n",
    "    model_input = predicted[:, i:i+1]\n",
    "    model_output = model.predict_on_batch(model_input)[0]\n",
    "    model_output += 0.25 * (np.random.rand(batch_size, 3) - 0.5)  # velocities: 0.25\n",
    "    \n",
    "    print 'Tr {}, step {}: In: {} - Out: {}'.format(log_traj, i, model_input[log_traj], model_output[log_traj]), \n",
    "    \n",
    "    if i+1 >= len_seed:\n",
    "        predicted[:, i+1] = model_output\n",
    "        print '--> Storing at {}'.format(i+1)\n",
    "    else:\n",
    "        print '--> Seed'\n",
    "\n",
    "expected = trajectories\n",
    "\n",
    "# TODO: Use end of the trajectory as seed and predict how it would continue.\n",
    "# PROBLEM: LSTM settles into equilibrium after a while, where it always outputs the same velocities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-18T18:00:17.607000",
     "start_time": "2016-03-18T18:00:16.990000"
    },
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot multiple trajectories from positions. \n",
    "i_traj = 0\n",
    "for i_traj in range(0, 200, 5):\n",
    "    pr = denormalize(predicted[i_traj])\n",
    "    plt.plot(pr[:, 0], pr[:, 1], label='Predicted')\n",
    "lim = 300#abs(max(np.min(pr), np.max(pr), np.min(exp), np.max(exp), key=abs)) + 20\n",
    "plt.xlim(-lim, lim)\n",
    "plt.ylim(-lim, lim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-18T18:05:32.528000",
     "start_time": "2016-03-18T18:05:32.175000"
    },
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# Plot single trajectory from velocities.\n",
    "i_traj = 20\n",
    "pr = to_positions(denormalize(predicted[i_traj]))\n",
    "plt.plot(pr[:, 0], pr[:, 1], label='Predicted')\n",
    "exp = to_positions(denormalize(expected[i_traj]))\n",
    "plt.plot(exp[:, 0], exp[:, 1], label='Expected')\n",
    "lim = abs(max(np.min(pr), np.max(pr), np.min(exp), np.max(exp), key=abs)) + 20\n",
    "plt.xlim(-lim, lim)\n",
    "plt.ylim(-lim, lim)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-18T18:06:02.190000",
     "start_time": "2016-03-18T18:06:01.666000"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot multiple trajectories from velocities.\n",
    "for i_traj in range(0, 200, 5):\n",
    "    pr = to_positions(denormalize(predicted[i_traj]))\n",
    "    plt.plot(pr[:, 0], pr[:, 1], label='Predicted')\n",
    "lim = 400#abs(max(np.min(pr), np.max(pr), np.min(exp), np.max(exp), key=abs)) + 20\n",
    "plt.xlim(-lim, lim)\n",
    "plt.ylim(-lim, lim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-18T18:06:08.845000",
     "start_time": "2016-03-18T18:06:08.347000"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make completely random trajectories.\n",
    "# TODO: Make random numbers at start of prediction, then feed them in one at a time. Thus, I can plot both the predicted trajectories and the \"random part\" of those trajectories.\n",
    "random_trajectories = 0.2 * (np.random.rand(batch_size, num_timesteps, 3) - 0.5)\n",
    "for i_traj in range(0, 200, 5):\n",
    "    pr = to_positions(denormalize(random_trajectories[i_traj]))\n",
    "    plt.plot(pr[:, 0], pr[:, 1], label='Random')\n",
    "lim = 50#abs(max(np.min(pr), np.max(pr), np.min(exp), np.max(exp), key=abs)) + 20\n",
    "plt.xlim(-lim, lim)\n",
    "plt.ylim(-lim, lim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-18T18:55:55.130000",
     "start_time": "2016-03-18T18:55:54.041000"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Predict with random values as seed.\n",
    "len_seed = 1\n",
    "predicted = np.zeros((batch_size, num_timesteps, 3))\n",
    "# Disable this line to predict on 0-inputs (due to the randomness, this also creates different trajectories).\n",
    "#predicted[:, :len_seed] = 2. * (np.random.rand(batch_size, len_seed, 3) - 0.5)\n",
    "model.reset_states()\n",
    "\n",
    "log_traj = 0\n",
    "    \n",
    "for i in range(num_timesteps - 1):\n",
    "    model_input = predicted[:, i:i+1]\n",
    "    model_output = model.predict_on_batch(model_input)[0]    \n",
    "    model_output += 0.25 * (np.random.rand(batch_size, 3) - 0.5)\n",
    "    \n",
    "    print 'Tr {}, step {}: In: {} - Out: {}'.format(log_traj, i, model_input[log_traj], model_output[log_traj]), \n",
    "    \n",
    "    if i+1 >= len_seed:\n",
    "        predicted[:, i+1] = model_output\n",
    "        print '--> Storing at {}'.format(i+1)\n",
    "    else:\n",
    "        print '--> Seed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2016-03-18T18:56:58.759000",
     "start_time": "2016-03-18T18:56:58.300000"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot multiple trajectories from velocities.\n",
    "for i_traj in range(0, 200, 5):\n",
    "    pr = to_positions(denormalize(predicted[i_traj]))\n",
    "    plt.plot(pr[:, 0], pr[:, 1], label='Predicted')\n",
    "lim = 300#abs(max(np.min(pr), np.max(pr), np.min(exp), np.max(exp), key=abs)) + 20\n",
    "plt.xlim(-lim, lim)\n",
    "plt.ylim(-lim, lim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
